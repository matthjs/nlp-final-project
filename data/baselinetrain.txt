2024-04-06 22:28:37.174 | INFO     | __main__:main:46 - Training model... (baseline)
Map: 100%|█████████████████████████████████████████████████████████████████████████████| 74160/74160 [00:35<00:00, 2073.43 examples/s]
Map: 100%|███████████████████████████████████████████████████████████████████████████████| 4212/4212 [00:02<00:00, 2101.76 examples/s]
Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/matthijs/programming/nlp-final-project/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
{'loss': 4.1193, 'grad_norm': 19.801753997802734, 'learning_rate': 1.9280834232290546e-05, 'epoch': 0.11}
{'loss': 2.7926, 'grad_norm': 20.850894927978516, 'learning_rate': 1.856166846458109e-05, 'epoch': 0.22}
{'loss': 2.5158, 'grad_norm': 27.66071891784668, 'learning_rate': 1.784250269687163e-05, 'epoch': 0.32}
{'loss': 2.2861, 'grad_norm': 21.037355422973633, 'learning_rate': 1.7123336929162174e-05, 'epoch': 0.43}
{'loss': 2.2185, 'grad_norm': 20.71833038330078, 'learning_rate': 1.6404171161452715e-05, 'epoch': 0.54}
{'loss': 2.1249, 'grad_norm': 24.897043228149414, 'learning_rate': 1.568500539374326e-05, 'epoch': 0.65}
{'loss': 2.0876, 'grad_norm': 18.81491470336914, 'learning_rate': 1.4965839626033803e-05, 'epoch': 0.76}
{'loss': 2.0009, 'grad_norm': 14.273802757263184, 'learning_rate': 1.4246673858324345e-05, 'epoch': 0.86}
{'loss': 1.9792, 'grad_norm': 15.349458694458008, 'learning_rate': 1.3527508090614887e-05, 'epoch': 0.97}
{'eval_loss': 1.910435438156128, 'eval_runtime': 35.3335, 'eval_samples_per_second': 119.207, 'eval_steps_per_second': 7.472, 'epoch': 1.0}
{'loss': 1.773, 'grad_norm': 33.177101135253906, 'learning_rate': 1.2808342322905431e-05, 'epoch': 1.08}
{'loss': 1.6794, 'grad_norm': 17.2955379486084, 'learning_rate': 1.2089176555195974e-05, 'epoch': 1.19}
{'loss': 1.6568, 'grad_norm': 14.55863094329834, 'learning_rate': 1.1370010787486516e-05, 'epoch': 1.29}
{'loss': 1.6616, 'grad_norm': 18.23855972290039, 'learning_rate': 1.0650845019777058e-05, 'epoch': 1.4}
{'loss': 1.6578, 'grad_norm': 19.12184715270996, 'learning_rate': 9.931679252067602e-06, 'epoch': 1.51}
{'loss': 1.6135, 'grad_norm': 20.90864372253418, 'learning_rate': 9.212513484358145e-06, 'epoch': 1.62}
{'loss': 1.6073, 'grad_norm': 19.85650062561035, 'learning_rate': 8.493347716648687e-06, 'epoch': 1.73}
{'loss': 1.6255, 'grad_norm': 21.374197006225586, 'learning_rate': 7.774181948939231e-06, 'epoch': 1.83}
{'loss': 1.6076, 'grad_norm': 16.559633255004883, 'learning_rate': 7.055016181229773e-06, 'epoch': 1.94}
{'eval_loss': 1.8007075786590576, 'eval_runtime': 35.4438, 'eval_samples_per_second': 118.836, 'eval_steps_per_second': 7.448, 'epoch': 2.0}
{'loss': 1.4959, 'grad_norm': 16.247020721435547, 'learning_rate': 6.335850413520317e-06, 'epoch': 2.05}
{'loss': 1.3442, 'grad_norm': 26.509654998779297, 'learning_rate': 5.6166846458108604e-06, 'epoch': 2.16}
{'loss': 1.3723, 'grad_norm': 22.843984603881836, 'learning_rate': 4.897518878101403e-06, 'epoch': 2.27}
{'loss': 1.3486, 'grad_norm': 17.526470184326172, 'learning_rate': 4.178353110391946e-06, 'epoch': 2.37}
{'loss': 1.374, 'grad_norm': 17.9852352142334, 'learning_rate': 3.4591873426824886e-06, 'epoch': 2.48}
{'loss': 1.345, 'grad_norm': 20.05888557434082, 'learning_rate': 2.7400215749730314e-06, 'epoch': 2.59}
{'loss': 1.3087, 'grad_norm': 20.784957885742188, 'learning_rate': 2.0208558072635745e-06, 'epoch': 2.7}
{'loss': 1.3229, 'grad_norm': 25.439973831176758, 'learning_rate': 1.3016900395541175e-06, 'epoch': 2.8}
{'loss': 1.3442, 'grad_norm': 18.3590087890625, 'learning_rate': 5.825242718446603e-07, 'epoch': 2.91}
{'eval_loss': 1.8161280155181885, 'eval_runtime': 35.0226, 'eval_samples_per_second': 120.265, 'eval_steps_per_second': 7.538, 'epoch': 3.0}
{'train_runtime': 7589.2666, 'train_samples_per_second': 29.315, 'train_steps_per_second': 1.832, 'train_loss': 1.8104647134714356, 'epoch': 3.0}
100%|█████████████████████████████████████████████████████████████████████████████████████████| 13905/13905 [2:06:29<00:00,  1.83it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████| 264/264 [00:34<00:00,  7.58it/s]